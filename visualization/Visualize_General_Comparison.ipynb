{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "import struct\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\"\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = \"../\"\n",
    "\n",
    "sel_dataset = \"speech_commands\"\n",
    "\n",
    "sel_attack  = \"deepfool\"  #DeepFool\n",
    "#sel_attack  = \"cw_l2\"    #Carlini & Wagner\n",
    "#sel_attack  = \"fgsm_v2\"  #Fast Gradient Sign Method\n",
    "#sel_attack  = \"rand_pgd\" #Projected Gradient Descent\n",
    "\n",
    "#Attack parameters\n",
    "if sel_attack==\"deepfool\":\n",
    "    overshoot_df = 0.02\n",
    "    max_iter_thr = 30\n",
    "    max_dist_vec = [0.0005, 0.001, 0.0025, 0.005, 0.01, 0.05, 0.1, 0.15] #l2 norm\n",
    "elif sel_attack in [\"cw_l2\"]:\n",
    "    max_iter_thr = 1000\n",
    "    max_dist_vec = [0.01, 0.05, 0.1, 0.15] #l2 norm\n",
    "elif sel_attack in [\"fgsm_v2\"]:\n",
    "    max_iter_thr = 1000\n",
    "    max_dist_vec = [0.00005, 0.0001, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02] #linf norms\n",
    "elif sel_attack in [\"rand_pgd\"]:\n",
    "    max_iter_thr = 30\n",
    "    max_dist_vec = [0.00005, 0.0001, 0.0005, 0.001, 0.002, 0.005] #linf norms\n",
    "else: sys.exit(\"Supported attacks: [deepfool, rand_pgd, cw_l2, fgsm_v2]\")\n",
    "\n",
    "    \n",
    "if sel_attack==\"deepfool\":\n",
    "    param_appendix_patt = \"_ov_%s\"%(str(overshoot_df)) + \"_eps_%s_iters_%d_start_%d_fold_%d.npy\"\n",
    "elif sel_attack in [\"rand_pgd\", \"cw_l2\", \"fgsm_v2\"]:\n",
    "    param_appendix_patt = \"_eps_%s_iters_%d_start_%d_fold_%d.npy\"\n",
    "else:\n",
    "    sys.exit(\"Attack not supported\")\n",
    "          \n",
    "#ID of the set of target distributions\n",
    "p_y_obj_set_idx = 1 #1: 100 random dirichlets, 2: uniform distribution (1/k,...1/k)\n",
    "validation_folder = root_path + \"optimization/validation/\"\n",
    "p_y_obj_set = np.load(validation_folder + \"p_y_obj_set_%d.npy\"%p_y_obj_set_idx)\n",
    "\n",
    "len(p_y_obj_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Configuration: main methods + baselines\n",
    "method_names  = [\"m1\", \"m2\",  \"m3\",   \"m4\",  \"mab\", \"mfrb\"]\n",
    "plot_labels   = [\"AM\", \"UBM\", \"EWTM\", \"CRM\", \"MAB\", \"MFRB\"]\n",
    "plot_colors   = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "marker_types  = [\"s\", \"o\", \"v\", \"^\", \"X\", \"*\"]\n",
    "get_prob_methods = [1, 1, 1, 1, 1, 1]\n",
    "\n",
    "##Configuration: main methods\n",
    "#method_names = [\"m1\", \"m2\",  \"m3\",   \"m4\"]\n",
    "#plot_labels  = [\"AM\", \"UBM\", \"EWTM\", \"CRM\"]\n",
    "#plot_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "#marker_types = [\"s\", \"o\", \"v\", \"^\"]\n",
    "#get_prob_methods = [1, 1, 1, 1]\n",
    "\n",
    "N_methods = len(method_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_per_class = 1000\n",
    "N_per_class_train = 500 #Number of samples used to generate the transition matrices\n",
    "\n",
    "N_multistarts = 50  #Number of k-fold cross validation repetitions\n",
    "N_folds = N_per_class//N_per_class_train #Number of folds in each cross-validation\n",
    "\n",
    "print(\"N_multistarts: %d\"%N_multistarts)\n",
    "print(\"N_folds: %d\"%N_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success in the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Global variable to store in which cases the transition matrices were generated (=1) or not (=0)\n",
    "#(that is, in which cases the linear program was successfully solved).\n",
    "success_ref_full = np.zeros((N_methods, len(max_dist_vec), N_multistarts, N_folds, len(p_y_obj_set)), dtype=int)\n",
    "\n",
    "#This variable will be used to summarize the results for each method and max. dist. threshold\n",
    "data_full = np.zeros((N_methods, len(max_dist_vec))) #Percentage of success\n",
    "\n",
    "for i_m in range(N_methods):\n",
    "    sel_method = method_names[i_m] #Method to be processed\n",
    "    \n",
    "    #Path containing the results for the current method & setup\n",
    "    results_root = root_path + \"optimization/%s/%s/results_%s/\"%(sel_dataset, sel_attack, sel_method)\n",
    "    load_path = results_root + \"p_y_obj_set_%d/\"%p_y_obj_set_idx\n",
    "    load_path = load_path    + \"N_train_%d/\"%(N_per_class_train)\n",
    "    print(load_path)\n",
    "    \n",
    "    for i_d in range(len(max_dist_vec)):\n",
    "        max_dist_thr = np.copy(max_dist_vec[i_d]) #Distance threshold\n",
    "        \n",
    "        #In this variable we will save, for each start, the average results of both folds.\n",
    "        #If for a target distribution at least in one fold the method failed, then, for that target \n",
    "        #distribution, we report failure for the whole start.\n",
    "        tmp_start_vec = np.zeros((len(p_y_obj_set), N_multistarts), dtype=int)\n",
    "        \n",
    "        for i_start in range(N_multistarts):\n",
    "            \n",
    "            #In this variable we will save the values of the current k-fold cross validation.\n",
    "            tmp_fold_vec = np.zeros((len(p_y_obj_set), N_folds), dtype=int)\n",
    "            \n",
    "            for i_fold in range(N_folds):\n",
    "                    \n",
    "                param_appendix = param_appendix_patt%(str(max_dist_thr), max_iter_thr, i_start, i_fold)\n",
    "                \n",
    "                #SUCCESS (for every target distribution in the set)\n",
    "                success_optimization = np.load(load_path + \"success_opt\" + param_appendix)\n",
    "                \n",
    "                #Save the results of the current fold\n",
    "                tmp_fold_vec[:,i_fold] = np.copy(success_optimization)\n",
    "                #Save the results of the current fold also in the global variable\n",
    "                success_ref_full[i_m,i_d,i_start,i_fold,:] = np.copy(success_optimization)\n",
    "                \n",
    "            #Average/reduce results by fold\n",
    "            for i in range(len(p_y_obj_set)):\n",
    "                #If for a target distribution at least in one fold the method failed, then, for that target \n",
    "                #distribution, we report failure for the whole start.\n",
    "                if np.any(tmp_fold_vec[i,:]==0): tmp_start_vec[i, i_start] = 0\n",
    "                else:                            tmp_start_vec[i, i_start] = 1\n",
    "                    \n",
    "        #Average/reduce results by multistart\n",
    "        #First average for each target dist. the results of all the multistarts\n",
    "        cur_val = np.mean(tmp_start_vec,axis=1)\n",
    "        if len(cur_val)!=len(p_y_obj_set): sys.exit(\"Wrong axis\")\n",
    "        \n",
    "        #Second, average those results (all the target distributions)\n",
    "        cur_val = np.mean(cur_val) \n",
    "        data_full[i_m, i_d] = np.copy(cur_val)*100\n",
    "        \n",
    "        #Sanity check\n",
    "        #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n",
    "        tmp_check = np.sum(tmp_start_vec)/(tmp_start_vec.shape[0]*tmp_start_vec.shape[1])\n",
    "        if np.abs(cur_val-tmp_check)>1e-8:\n",
    "            sys.exit(\"Means are not the same\")\n",
    "        #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Print the results\n",
    "np.round(data_full,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fooling rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum possible fooling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Note that the maximum possible fooling rate only depends on the validation set, not on the target prob. distr.\n",
    "fr_clean_full = np.zeros((N_methods, len(max_dist_vec), N_multistarts, N_folds))\n",
    "\n",
    "for i_d in range(len(max_dist_vec)):\n",
    "    max_dist_thr = max_dist_vec[i_d] #Current max. distortion threshold\n",
    "    \n",
    "    for i_start in range(N_multistarts):\n",
    "        for i_fold in range(N_folds):\n",
    "            for i_m in range(N_methods):\n",
    "                sel_method = method_names[i_m] #Current method\n",
    "                \n",
    "                #Compute the clean fooling rate\n",
    "                results_root = root_path + \"optimization/%s/%s/results_%s/\"%(sel_dataset, sel_attack, sel_method)\n",
    "                load_path = results_root + \"p_y_obj_set_%d/\"%p_y_obj_set_idx\n",
    "                load_path = load_path    + \"N_train_%d/\"%(N_per_class_train)\n",
    "                    \n",
    "                param_appendix = param_appendix_patt%(str(max_dist_thr), max_iter_thr, i_start, i_fold)\n",
    "                    \n",
    "                #Load the optimum fooling rate (proportion of inputs for which a successful targeted attack was created)\n",
    "                opt_fr = np.load(load_path + \"opt_fr\" + param_appendix)\n",
    "                #Store the value\n",
    "                fr_clean_full[i_m,i_d,i_start,i_fold] = np.copy(opt_fr)\n",
    "            \n",
    "            #Sanity check: all the methods have the same values\n",
    "            for i_m in range(N_methods-1):\n",
    "                tmp_val1 = np.copy(fr_clean_full[i_m,  i_d,i_start,i_fold])\n",
    "                tmp_val2 = np.copy(fr_clean_full[i_m+1,i_d,i_start,i_fold])\n",
    "                if np.abs(tmp_val1 - tmp_val2)>1e-8: sys.exit(\"Not the same opt FR???\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achieved fooling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average fooling rate (for each method and distortion threshold)\n",
    "fr_adv_full    = np.zeros((N_methods, len(max_dist_vec)))\n",
    "\n",
    "\n",
    "for i_m in range(N_methods):\n",
    "    sel_method = method_names[i_m] #Current method\n",
    "    \n",
    "    for i_d in range(len(max_dist_vec)):\n",
    "        max_dist_thr = np.copy(max_dist_vec[i_d]) #Current max. dist. threshold\n",
    "        \n",
    "        #In this variable we will save, for each start, the average results of all the k-fold trials.\n",
    "        tmp_start_fr_vec    = np.zeros((len(p_y_obj_set), N_multistarts))\n",
    "        \n",
    "        for i_start in range(N_multistarts):\n",
    "            \n",
    "            #In this variable we will save the values of the current k-fold cross validation.\n",
    "            tmp_fold_fr_vec   = np.zeros((len(p_y_obj_set), N_folds))\n",
    "            \n",
    "            for i_fold in range(N_folds):\n",
    "                #Set the path and the filename\n",
    "                results_root = root_path + \"optimization/%s/%s/results_%s/\"%(sel_dataset, sel_attack, sel_method)\n",
    "                load_path = results_root + \"p_y_obj_set_%d/\"%p_y_obj_set_idx\n",
    "                load_path = load_path    + \"N_train_%d/\"%(N_per_class_train)\n",
    "                \n",
    "                param_appendix = param_appendix_patt%(str(max_dist_thr), max_iter_thr, i_start, i_fold)\n",
    "                    \n",
    "                #Load the SUCCESS and FR\n",
    "                success_opt   = np.load(load_path + \"success_opt\" + param_appendix)\n",
    "                fooling_rates = np.load(load_path + \"fr\"          + param_appendix)\n",
    "                \n",
    "                #Sanity check\n",
    "                if np.any(success_opt!=success_ref_full[i_m,i_d,i_start,i_fold,:]): sys.exit(\"Check success\")\n",
    "                \n",
    "                #Store the value\n",
    "                tmp_fold_fr_vec[:,i_fold] = np.copy(fooling_rates)\n",
    "\n",
    "                \n",
    "            #Average/reduce results by fold \n",
    "            #(later those starts in which one of the folds failed will be discarded)\n",
    "            tmp_start_fr_vec[:,i_start] = np.mean(tmp_fold_fr_vec, axis=1)\n",
    "            \n",
    "            #Sanity check\n",
    "            if len(np.mean(tmp_fold_fr_vec, axis=1))!=len(p_y_obj_set): sys.exit(\"Wrong axis\")\n",
    "            \n",
    "        \n",
    "        #Auxiliary variable to store the average results for each target distribution\n",
    "        tmp_pyobj_fr_vec = np.zeros(len(p_y_obj_set))\n",
    "        #Auxiliary variable to store for which target distribution there are results to be averaged\n",
    "        mask_pyobj_with_any_success = np.zeros(len(p_y_obj_set), dtype=int)\n",
    "        \n",
    "        for i_p in range(len(p_y_obj_set)): \n",
    "            #Mask which indicates, given the current target distribution, for which starts at least one fold failed\n",
    "            mask_success_start = np.zeros(N_multistarts, dtype=int)\n",
    "            for i_start in range(N_multistarts):\n",
    "                if np.any(success_ref_full[i_m,i_d,i_start,:,i_p]==0): mask_success_start[i_start] = 0\n",
    "                else                                                 : mask_success_start[i_start] = 1\n",
    "            \n",
    "            #If at least in one start there are not fails, average those results\n",
    "            if not np.all(mask_success_start==0):\n",
    "                #Compute the average results for the current target distributions\n",
    "                tmp_pyobj_fr_vec[i_p] = np.mean(tmp_start_fr_vec[i_p,mask_success_start==1])\n",
    "                if np.any(tmp_start_fr_vec[i_p,mask_success_start==1]!=tmp_start_fr_vec[i_p,:][mask_success_start==1]):\n",
    "                    sys.exit(\"Check maskings\")\n",
    "                \n",
    "                #Mark that for the current target distribution there are values to be averaged\n",
    "                mask_pyobj_with_any_success[i_p] = 1\n",
    "            else:\n",
    "                #Mark that for the current target distribution there are NOT values to be averaged\n",
    "                mask_pyobj_with_any_success[i_p] = 0\n",
    "        \n",
    "        \n",
    "        #Finally, average the results obtained for all the target distributions\n",
    "        if np.all(mask_pyobj_with_any_success==0):\n",
    "            print(\"(%s - %s) --> All the results failed\"%(method_names[i_m], str(max_dist_vec[i_d])))\n",
    "            fr_adv_full[i_m, i_d] = np.nan\n",
    "        else:\n",
    "            fr_adv_full[i_m, i_d] = np.mean(tmp_pyobj_fr_vec[mask_pyobj_with_any_success==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot the obtained fooling rates\n",
    "np.zeros((N_methods, len(max_dist_vec), N_multistarts, N_folds))\n",
    "matplotlib.rc('figure', figsize=(6, 4))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#Take the results corresponding to the first method (the results are the same for all the methods)\n",
    "red_fr_clean_full = np.copy(fr_clean_full[0,:,:,:]) \n",
    "#Average by folds\n",
    "red_fr_clean_full = np.mean(red_fr_clean_full, axis=2)\n",
    "#Sanity check\n",
    "if red_fr_clean_full.shape!=(len(max_dist_vec), N_multistarts): sys.exit(\"Wrong axis (1)\")\n",
    "#Average by starts\n",
    "red_fr_clean_full = np.mean(red_fr_clean_full, axis=1)\n",
    "#Sanity check\n",
    "if red_fr_clean_full.shape!=(len(max_dist_vec),): sys.exit(\"Wrong axis (2)\")\n",
    "\n",
    "#Plot the maximum fooling rates\n",
    "ax.plot(red_fr_clean_full*100, label=\"Max. fooling rate\", marker=\"d\", color=\"black\", linewidth=2, markersize=9)\n",
    "\n",
    "#Plot the fooling rates\n",
    "for i_m in range(N_methods):\n",
    "    ax.plot(fr_adv_full[i_m,:]*100, label=plot_labels[i_m], marker=marker_types[i_m], alpha=0.85, color=plot_colors[i_m])\n",
    "\n",
    "    #Sanity check\n",
    "    if np.any(fr_adv_full[i_m,:]>red_fr_clean_full):\n",
    "        if np.any(np.abs(fr_adv_full[i_m,:]-red_fr_clean_full)>1e-8):\n",
    "            sys.exit(\"AN EMPIRICAL FR > OPT FR!!!\")\n",
    "    \n",
    "ax.set_xlabel('$\\epsilon$', size=25, labelpad=-12)\n",
    "ax.set_ylabel('Fooling rate (%)', size=15, labelpad=-5)\n",
    "ax.set_xticks(range(len(max_dist_vec)))\n",
    "ax.set_xticklabels(max_dist_vec, size=12, rotation=30)\n",
    "ax.tick_params(axis=\"y\", which='major', labelsize=12)\n",
    "ax.tick_params(axis=\"x\", which='major', labelsize=12, pad=0)\n",
    "ax.set_ylim([-3,105])\n",
    "plt.title(\"\\nFooling rate percentage\", size=14)\n",
    "fig.tight_layout()\n",
    "matplotlib.pyplot.gcf().set_size_inches(4, 3.6)\n",
    "\n",
    "#Save figure without legend\n",
    "plt.savefig(\"/tmp/%s_fooling_rates_noleg.pdf\"%sel_attack, bbox_inches='tight', dpi=350)\n",
    "\n",
    "plt.legend(fontsize=12, borderaxespad=0.25, loc='upper left', framealpha=0.0, labelspacing=0.14)\n",
    "#plt.legend(fontsize=12, borderaxespad=0.25, loc='lower right', framealpha=0.0, labelspacing=0.2) #for cw_l2 and rand_pgd\n",
    "\n",
    "#Save figure with legend\n",
    "plt.savefig(\"/tmp/%s_fooling_rates.pdf\"%sel_attack, bbox_inches='tight', dpi=350)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot the results in tabular format\n",
    "for i in range(fr_adv_full.shape[0]):\n",
    "    data_to_tab = \" & \".join(map(str,np.round(fr_adv_full[i,:]*100,2)))\n",
    "    print(plot_labels[i] + \" & \" + data_to_tab + \" \\\\\\\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Maximum fooling rate\n",
    "np.round(red_fr_clean_full*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2) Distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some formatted labels\n",
    "p_orig_str = \"$\\mathcal{P}(Y)$\"\n",
    "p_obj_str = \"$\\widetilde{\\mathcal{P}}(Y)$\"\n",
    "p_emp_str = \"$\\hat{\\mathcal{P}}(Y)$\"\n",
    "#Short metric identifiers (\"ID\"s)\n",
    "metric_vec = [\"kl_obj\", \"kl_orig\", \"kl_orig_obj\", \n",
    "              \"max_dif_obj\", \"mean_dif_obj\", \"max_dif_orig\", \"mean_dif_orig\",\n",
    "              \"spearman_obj\", \"pearson_obj\", \"success_opt\"]\n",
    "#Explanation of each metric\n",
    "metric_expls = [\"KL divergence \\n between %s and %s\"%(p_obj_str, p_emp_str),\n",
    "               \"KL divergence \\n between %s and %s\"%(p_orig_str, p_emp_str),\n",
    "               \"KL divergence \\n between %s and %s\"%(p_orig_str, p_obj_str),\n",
    "               \"Max. abs. difference\\nbetween %s and %s\"%(p_obj_str, p_emp_str),\n",
    "               \"Mean abs. difference\\nbetween %s and %s\"%(p_obj_str, p_emp_str),\n",
    "               \"Max. abs. difference\\nbetween %s and %s\"%(p_orig_str, p_emp_str),\n",
    "               \"Mean abs. difference\\nbetween %s and %s\"%(p_orig_str, p_emp_str),\n",
    "               \"Spearman correlation\\nbetween %s and %s\"%(p_obj_str, p_emp_str),\n",
    "               \"Pearson correlation\\nbetween %s and %s\"%(p_obj_str, p_emp_str),\n",
    "               \"Success\\nin generating a valid transition matrix $T$\"]\n",
    "#Vertical axis table for each metric\n",
    "ylabels = [\"$D_{KL}$(%s, %s)\"%(p_obj_str, p_emp_str),\n",
    "          \"$D_{KL}$(%s, %s)\"%(p_orig_str, p_emp_str),\n",
    "          \"$D_{KL}$(%s, %s)\"%(p_orig_str, p_obj_str),\n",
    "          \"Max abs. difference\", \"Mean abs. difference\",\n",
    "          \"Max abs. difference\", \"Mean abs. difference\",\n",
    "          \"Correlation\", \"Correlation\", \"Success rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#General function to compute the results given the desired performance metric\n",
    "def get_performance(metric, method_names, get_prob_methods):\n",
    "    \n",
    "    print(\"Metric: \", metric)\n",
    "    \n",
    "    #Sanity check\n",
    "    if len(method_names)!=N_methods: sys.exit(\"You passed less method names than N_methods!\")\n",
    "\n",
    "    \n",
    "    #Variable to store the average results of each method and distortion threshold\n",
    "    data_full = np.zeros((N_methods, len(max_dist_vec)))\n",
    "    \n",
    "    \n",
    "    for i_m in range(N_methods):\n",
    "        sel_method = method_names[i_m] #Current method\n",
    "        \n",
    "        #Load paths\n",
    "        results_root = root_path + \"optimization/%s/%s/results_%s/\"%(sel_dataset, sel_attack, sel_method)\n",
    "        load_path = results_root + \"p_y_obj_set_%d/\"%p_y_obj_set_idx\n",
    "        load_path = load_path    + \"N_train_%d/\"%(N_per_class_train)\n",
    "        print(load_path)\n",
    "        \n",
    "        get_row_probs_method = np.copy(get_prob_methods[i_m])\n",
    "\n",
    "        for i_d in range(len(max_dist_vec)):\n",
    "            max_dist_thr = np.copy(max_dist_vec[i_d])  #Current distortion threshold\n",
    "                \n",
    "            #In this variable we will save, for each start, the average results of all the k-fold trials.\n",
    "            tmp_start_vec     = np.zeros((len(p_y_obj_set), N_multistarts))\n",
    "\n",
    "            for i_start in range(N_multistarts):\n",
    "\n",
    "                #In this variable we will save the values of the current k-fold cross validation.\n",
    "                tmp_fold_vec = np.zeros((len(p_y_obj_set), N_folds))\n",
    "\n",
    "                for i_fold in range(N_folds):\n",
    "\n",
    "                    #Compute the clean fooling rate\n",
    "                    results_root = root_path + \"optimization/%s/%s/results_%s/\"%(sel_dataset, sel_attack, sel_method)\n",
    "                    load_path = results_root + \"p_y_obj_set_%d/\"%p_y_obj_set_idx\n",
    "                    load_path = load_path    + \"N_train_%d/\"%(N_per_class_train)\n",
    "\n",
    "                    param_appendix = param_appendix_patt%(str(max_dist_thr), max_iter_thr, i_start, i_fold)\n",
    "\n",
    "                    #Load the SUCCESS and the RESULTS OBTAINED WITH THE SPECIFIED METRIC\n",
    "                    success_opt = np.load(load_path + \"success_opt\" + param_appendix)\n",
    "                    data        = np.load(load_path +  metric       + param_appendix)\n",
    "\n",
    "                    #Sanity checks\n",
    "                    if np.any(success_opt!=success_ref_full[i_m,i_d,i_start,i_fold,:]):\n",
    "                        sys.exit(\"Check success\")\n",
    "                        \n",
    "                    #Store the value\n",
    "                    tmp_fold_vec[:,i_fold] = np.copy(data)\n",
    "\n",
    "\n",
    "                #Average/reduce results by fold \n",
    "                #(later those starts in which one of the folds failed will be discarded)\n",
    "                tmp_start_vec[:,i_start] = np.mean(tmp_fold_vec, axis=1)\n",
    "\n",
    "            \n",
    "            #Auxiliary variable to store the average results for each target distribution\n",
    "            tmp_pyobj_vec = np.zeros(len(p_y_obj_set))\n",
    "            #Auxiliary variable to store for which target distribution there are results to be averaged\n",
    "            mask_pyobj_with_any_success = np.zeros(len(p_y_obj_set), dtype=int)\n",
    "            \n",
    "            for i_p in range(len(p_y_obj_set)): \n",
    "                \n",
    "                #Mask which indicates, given the current target distribution, for which starts at least one fold failed\n",
    "                mask_success_start = np.zeros(N_multistarts, dtype=int)\n",
    "                for i_start in range(N_multistarts):\n",
    "                    if np.any(success_ref_full[i_m,i_d,i_start,:,i_p]==0): mask_success_start[i_start] = 0\n",
    "                    else                                                 : mask_success_start[i_start] = 1\n",
    "                \n",
    "                #If at least in one start there are not fails, average those results\n",
    "                if not np.all(mask_success_start==0):\n",
    "                    #Compute the average results for the current target distributions\n",
    "                    tmp_pyobj_vec[i_p] = np.mean(tmp_start_vec[i_p,mask_success_start==1])\n",
    "                    #Mark that for the current target distribution there are values to be averaged\n",
    "                    mask_pyobj_with_any_success[i_p] = 1\n",
    "                else:\n",
    "                    #Mark that for the current target distribution there are NOT values to be averaged\n",
    "                    mask_pyobj_with_any_success[i_p] = 0\n",
    "\n",
    "            #Finally, average the results obtained for all the target distributions\n",
    "            if np.all(mask_pyobj_with_any_success==0):\n",
    "                print(\"(%s - %s) --> All the results failed\"%(method_names[i_m], str(max_dist_vec[i_d])))\n",
    "                data_full[i_m, i_d] = np.nan\n",
    "            else:\n",
    "                data_full[i_m, i_d] = np.mean(tmp_pyobj_vec[mask_pyobj_with_any_success==1])\n",
    "            \n",
    "    return data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i_metric in range(len(metric_vec)):\n",
    "                    \n",
    "    metric = metric_vec[i_metric]   #Current metric identifier\n",
    "    expl   = metric_expls[i_metric] #Current metric explanation\n",
    "    \n",
    "    #Compute the average results\n",
    "    data_full = get_performance(metric, method_names, get_prob_methods)\n",
    "    print(np.round(data_full,4))\n",
    "    \n",
    "    \n",
    "    #Visualize the results\n",
    "    matplotlib.rc('figure', figsize=(6, 4))\n",
    "    \n",
    "    #Plot the results for each method\n",
    "    for i_m in range(N_methods):\n",
    "        plt.plot(data_full[i_m,:], label=plot_labels[i_m], marker=marker_types[i_m], color=plot_colors[i_m])\n",
    "\n",
    "    plt.xlabel('$\\epsilon$', size=25, labelpad=-12)\n",
    "    plt.ylabel(ylabels[i_metric], size=15)\n",
    "    plt.xticks(range(len(max_dist_vec)), max_dist_vec, size=12, rotation=30)\n",
    "    plt.yticks(size=12)\n",
    "    #ax.set_ylim([20,100])\n",
    "    plt.title(\"%s\"%expl, size=15)\n",
    "    fig.tight_layout()\n",
    "    matplotlib.pyplot.gcf().set_size_inches(4.3, 3)\n",
    "    \n",
    "    #Save figure without legend\n",
    "    plt.savefig(\"/tmp/%s_comp_%s_noleg.pdf\"%(sel_attack, metric), bbox_inches='tight', dpi=300)\n",
    "    plt.legend(fontsize=11.5, framealpha=0.5, labelspacing=0.1)\n",
    "    \n",
    "    #Save figure with legend\n",
    "    plt.savefig(\"/tmp/%s_comp_%s.pdf\"%(sel_attack, metric), bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pareto plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_marker_types = [\".\", \"P\", \"v\", \"^\", \"H\", \"s\", \"<\", \">\"] #markers for the distortion thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Auxiliary front to select those values that form the \"Pareto front\".\n",
    "#The default criterion is to minimize all the factors.\n",
    "#The comparison between values can be 'strict' (i.e., <) or 'non-strict' (i.e., <=), determined by the boolean\n",
    "#values passed to the 'strict' argument.\n",
    "def get_pareto_front_one(values, strict=True):\n",
    "    is_efficient = np.ones(values.shape[0], dtype = bool)\n",
    "    for i, v in enumerate(values):\n",
    "        if is_efficient[i]:\n",
    "            if strict:\n",
    "                is_efficient[is_efficient] = np.any(values[is_efficient]<v, axis=1)\n",
    "            else:\n",
    "                is_efficient[is_efficient] = np.any(values[is_efficient]<=v, axis=1)\n",
    "            is_efficient[i] = True\n",
    "    return is_efficient\n",
    "\n",
    "#c1 and c2 control whether the values of data1 and data2, respectively, should be minimized (=1.0) or maximized (=-1.0).\n",
    "def get_pareto_front_all(data1, data2, c1=1.0, c2=1.0, strict=True):\n",
    "    assert data1.shape==data2.shape\n",
    "    pareto_mask  = np.zeros(data1.shape, dtype=bool) #Boolean array. True if a value is in the pareto front\n",
    "    pareto_order = np.zeros(data1.shape, dtype=int)  #Array to store the \"order\" of the values in the pareto set\n",
    "    for i_d in range(data1.shape[1]):\n",
    "        #Compute which values are in the pareto front\n",
    "        cur_values = np.array((c1*data1[:,i_d], c2*data2[:,i_d])).T\n",
    "        pareto_mask[:,i_d] = get_pareto_front_one(cur_values, strict)\n",
    "        #\"Order\" of the values in the pareto front\n",
    "        cur_vals_pareto    = np.copy(-cur_values[pareto_mask[:,i_d],:])\n",
    "        pareto_order[pareto_mask[:,i_d],i_d] = np.lexsort((cur_vals_pareto[:,0], cur_vals_pareto[:,1]))\n",
    "\n",
    "    return pareto_mask, pareto_order\n",
    "\n",
    "\n",
    "#Plot pareto front\n",
    "def plot_scatter_pareto(data1, data2, pareto_mask, pareto_order, plot_colors, cur_marker_types, plt):\n",
    "    for i_d in range(data1.shape[1]):\n",
    "        #plot line between those values corresponding to the same distortion threshold\n",
    "        data1_pareto = np.copy(data1[pareto_mask[:,i_d], :]) #get the values in the pareto front\n",
    "        data2_pareto = np.copy(data2[pareto_mask[:,i_d], :]) #get the values in the pareto front\n",
    "        cur_pareto_order_idx = np.copy(pareto_order[pareto_mask[:,i_d],i_d]) #order\n",
    "        plt.plot(data1_pareto[cur_pareto_order_idx,i_d], data2_pareto[cur_pareto_order_idx,i_d], \n",
    "                 color=\"black\", alpha=0.35, linestyle=\":\")\n",
    "\n",
    "        #Plot the value corresponding to each method individually\n",
    "        for i_m in range(data1.shape[0]):\n",
    "            #Plot the current value\n",
    "            cur_alpha = 0.85 if pareto_mask[i_m,i_d] else 0.65\n",
    "            #cur_alpha = 0.85 if pareto_mask[i_m,i_d] else 0.45\n",
    "            cur_edgecolor = plot_colors[i_m] #if pareto_mask[i_m,i_d] else \"white\"\n",
    "            cur_facecolor = plot_colors[i_m] if pareto_mask[i_m,i_d] else \"none\"\n",
    "            plt.scatter(data1[i_m,i_d], data2[i_m,i_d], facecolors=cur_facecolor, edgecolors=plot_colors[i_m],\n",
    "                        marker=cur_marker_types[i_d], s=80, alpha=cur_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spearman correlation & fooling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = np.copy(fr_adv_full)\n",
    "\n",
    "metric2_idx = np.where(np.array(metric_vec)==\"spearman_obj\")[0][0]\n",
    "data2 = get_performance(metric_vec[metric2_idx], method_names, get_prob_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data1 (Fooling rate)--> maximize\n",
    "#Data2 (Correlation) --> maximize\n",
    "pareto_mask, pareto_order = get_pareto_front_all(data1, data2, c1=-1.0, c2=-1.0, strict=True)\n",
    "\n",
    "\n",
    "#Visualize the results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_scatter_pareto(data1, data2, pareto_mask, pareto_order, plot_colors, cur_marker_types, plt)\n",
    "        \n",
    "#Formatting...\n",
    "plt.xlim(1.0, np.min(data1) -0.03)\n",
    "plt.ylim(np.max(data2)+0.05, np.min(data2) -0.03)\n",
    "plt.xlabel(\"Fooling rate\", size=14)\n",
    "plt.ylabel(ylabels[metric2_idx], size=14)\n",
    "plt.xticks(size=12) ; plt.yticks(size=12)\n",
    "#Inset axes\n",
    "zoom_x1, zoom_x2, zoom_y1, zoom_y2 = 0.97, 0.69, 0.92, 0.795\n",
    "plt.arrow(0.84, 0.77, -0.03, -0.21, head_width=0.025, head_length=0.04, color=\"black\", linewidth=0.2, linestyle=\"-\")\n",
    "ax2 = plt.axes([.138, .5, .27, .35], facecolor='none')\n",
    "plt.setp(ax2, xticks=[], yticks=[])\n",
    "plot_scatter_pareto(data1, data2, pareto_mask, pareto_order, plot_colors, cur_marker_types, ax2)\n",
    "ax2.set_xlim(zoom_x1, zoom_x2)\n",
    "ax2.set_ylim(zoom_y1, zoom_y2)        \n",
    "rect = Rectangle((0.69, 0.77), 0.285, 0.17, edgecolor=\"black\", lw=1.0, facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "matplotlib.pyplot.gcf().set_size_inches(5, 3.5)\n",
    "\n",
    "#Save figure\n",
    "plt.savefig(\"/tmp/pareto_corr_fr.pdf\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum absolute difference & fooling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = np.copy(fr_adv_full)\n",
    "\n",
    "metric2_idx = np.where(np.array(metric_vec)==\"max_dif_obj\")[0][0]\n",
    "data2 = get_performance(metric_vec[metric2_idx], method_names, get_prob_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data1 (Fooling rate)--> maximize\n",
    "#Data2 (max. dif.)   --> minimize\n",
    "pareto_mask, pareto_order = get_pareto_front_all(data1, data2, c1=-1.0, c2=1.0, strict=True)\n",
    "\n",
    "#Visualize the results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_scatter_pareto(data1, data2, pareto_mask, pareto_order, plot_colors, cur_marker_types, plt)\n",
    "\n",
    "        \n",
    "#Formatting...\n",
    "plt.xlim(np.nanmax(data1)+0.05, np.nanmin(data1) -0.03)\n",
    "plt.ylim(np.nanmin(data2)-0.005, np.nanmax(data2) + 0.005)\n",
    "plt.xlabel(\"Fooling rate\", size=14)\n",
    "plt.ylabel(ylabels[metric2_idx], size=14)\n",
    "plt.xticks(size=12) ; plt.yticks(size=12)\n",
    "plt.rc('ytick', labelsize=11)\n",
    "plt.xlim(1,-0.02)\n",
    "\n",
    "matplotlib.pyplot.gcf().set_size_inches(5, 3.5)\n",
    "\n",
    "#Save the figure\n",
    "plt.savefig(\"/tmp/pareto_max_fr.pdf\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pareto Plots with the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the positions of each method in the horizontal axis\n",
    "base_x_ticks = np.array([0.5]*len(max_dist_vec))\n",
    "data1 = np.vstack((np.array([0]*len(max_dist_vec)), np.array([0]*len(max_dist_vec)),\n",
    "                   base_x_ticks, base_x_ticks, base_x_ticks, \n",
    "                   np.array([1]*len(max_dist_vec))))\n",
    "#Sort the data by the order of appearance (in this case by the order of parameters):\n",
    "data1 = np.copy(data1[[2,3,4,5,0,1],:]) #Order: MAB, MFBR,   AM, UBM, EWTM,   CRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean difference & Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric2_idx = np.where(np.array(metric_vec)==\"mean_dif_obj\")[0][0]\n",
    "data2 = get_performance(metric_vec[metric2_idx], method_names, get_prob_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data1 (# of parameters)--> minimize\n",
    "#Data2 (mean. dif.)     --> minimize\n",
    "pareto_mask, pareto_order = get_pareto_front_all(data1, data2, c1=1.0, c2=1.0, strict=True)\n",
    "\n",
    "#Visualize the results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_scatter_pareto(data1, data2, pareto_mask, pareto_order, plot_colors, cur_marker_types, plt)\n",
    "    \n",
    "#Formatting...\n",
    "plt.xlim(-0.2,1.2)\n",
    "plt.xticks([0.0, 0.5, 1],[\"$O(k)$\", \"$O(k^2)$\",\"$O(2^kk^2)$\"], size=17, y=0)\n",
    "plt.yticks(size=12)\n",
    "plt.ylim(np.nanmin(data2)-0.002, np.nanmax(data2)+0.002)\n",
    "plt.xlabel(\"Number of parameters\", size=14, labelpad=0)\n",
    "plt.ylabel(ylabels[metric2_idx], size=14)\n",
    "\n",
    "matplotlib.pyplot.gcf().set_size_inches(5, 3.5)\n",
    "\n",
    "#Save the figure\n",
    "plt.savefig(\"/tmp/pareto_params_mean.pdf\", bbox_inches='tight', dpi=350)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_marker_types = [\".\", \"P\", \"v\", \"^\", \"H\", \"s\", \"<\", \">\"]\n",
    "plt.plot()\n",
    "\n",
    "legend_elems = []\n",
    "legend_elems2 = []\n",
    "\n",
    "#col 1\n",
    "legend_elems.append(Line2D([0], [0], marker=cur_marker_types[0],label=\"$\\epsilon=$\"+str(max_dist_vec[0]),\n",
    "                            color=\"white\", markerfacecolor=\"grey\", markersize=13)) #Distortion\n",
    "legend_elems.append(Line2D([0], [0], marker=\"\", color=\"white\", markerfacecolor=\"white\", label=\"\")) #empty\n",
    "#col 2\n",
    "legend_elems.append(Line2D([0], [0], marker=cur_marker_types[1],label=\"$\\epsilon=$\"+str(max_dist_vec[1]),\n",
    "                            color=\"white\", markerfacecolor=\"grey\", markersize=13)) #Distortion\n",
    "legend_elems.append(Line2D([0], [0], marker=\"o\",color=\"white\", markerfacecolor=plot_colors[0], \n",
    "                           label=plot_labels[0], markersize=13)) #Method\n",
    "#col 3\n",
    "legend_elems.append(Line2D([0], [0], marker=cur_marker_types[2],label=\"$\\epsilon=$\"+str(max_dist_vec[2]),\n",
    "                            color=\"white\", markerfacecolor=\"grey\", markersize=13)) #Distortion\n",
    "legend_elems.append(Line2D([0], [0], marker=\"o\",color=\"white\", markerfacecolor=plot_colors[1], \n",
    "                           label=plot_labels[1], markersize=13)) #Method\n",
    "#col 4\n",
    "legend_elems.append(Line2D([0], [0], marker=cur_marker_types[3],label=\"$\\epsilon=$\"+str(max_dist_vec[3]),\n",
    "                            color=\"white\", markerfacecolor=\"grey\", markersize=13)) #Distortion\n",
    "legend_elems.append(Line2D([0], [0], marker=\"o\",color=\"white\", markerfacecolor=plot_colors[2], \n",
    "                           label=plot_labels[2], markersize=13)) #Method\n",
    "#col 5\n",
    "legend_elems.append(Line2D([0], [0], marker=cur_marker_types[4],label=\"$\\epsilon=$\"+str(max_dist_vec[4]),\n",
    "                            color=\"white\", markerfacecolor=\"grey\", markersize=13)) #Distortion\n",
    "legend_elems.append(Line2D([0], [0], marker=\"o\",color=\"white\", markerfacecolor=plot_colors[3], \n",
    "                           label=plot_labels[3], markersize=13)) #Method\n",
    "#col 6\n",
    "legend_elems.append(Line2D([0], [0], marker=cur_marker_types[5],label=\"$\\epsilon=$\"+str(max_dist_vec[5]),\n",
    "                            color=\"white\", markerfacecolor=\"grey\", markersize=13)) #Distortion\n",
    "legend_elems.append(Line2D([0], [0], marker=\"o\",color=\"white\", markerfacecolor=plot_colors[4], \n",
    "                           label=plot_labels[4], markersize=13)) #Method\n",
    "#col 7\n",
    "legend_elems.append(Line2D([0], [0], marker=cur_marker_types[6],label=\"$\\epsilon=$\"+str(max_dist_vec[6]),\n",
    "                            color=\"white\", markerfacecolor=\"grey\", markersize=13)) #Distortion\n",
    "legend_elems.append(Line2D([0], [0], marker=\"o\",color=\"white\", markerfacecolor=plot_colors[5], \n",
    "                           label=plot_labels[5], markersize=13)) #Method\n",
    "#col 8\n",
    "legend_elems.append(Line2D([0], [0], marker=cur_marker_types[7],label=\"$\\epsilon=$\"+str(max_dist_vec[7]),\n",
    "                            color=\"white\", markerfacecolor=\"grey\", markersize=13)) #Distortion\n",
    "#legend_elems2.append(Line2D([0], [0], marker=\"\", color=\"white\", markerfacecolor=\"white\", label=\"\")) #empty\n",
    "\n",
    "legend = plt.legend(handles=legend_elems, ncol=8, columnspacing=-0.0, handletextpad=-0.2, fontsize=11, \n",
    "           borderpad=0.3, frameon=True, borderaxespad=0.15, bbox_to_anchor=(0.96, 1.2))\n",
    "\n",
    "fig   = legend.figure\n",
    "fig.canvas.draw()\n",
    "bbox  = legend.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "fig.savefig(\"/tmp/legend_pareto.pdf\", dpi=\"figure\", bbox_inches=bbox)\n",
    "plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
