{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the working directory to load the utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import os.path\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../../\"\n",
    "\n",
    "sel_dataset = \"emotion\"\n",
    "print(\"Main setup: \\t \" + sel_dataset)\n",
    "\n",
    "#Load the problem labels\n",
    "labels_file_path = root_path + \"datasets/%s_dataset_train/%s_labels.txt\" % (sel_dataset, sel_dataset)\n",
    "labels = open(labels_file_path, 'r').readlines()\n",
    "labels = [s.rstrip() for s in labels]\n",
    "print(\"Labels\", labels)\n",
    "\n",
    "num_classes = len(labels) #Number of classes\n",
    "\n",
    "#Selected attack\n",
    "sel_attack = \"genetic\"\n",
    "print(\"Selected attack: %s\" % sel_attack)\n",
    "\n",
    "#Thresholds\n",
    "max_iter_thr = np.inf  #Number of iterations\n",
    "max_dist_thr = 0.25    #Epsilon\n",
    "\n",
    "#Path containing the results:\n",
    "load_path = root_path + \"optimization/label_shift/%s/%s/\" % (sel_dataset, sel_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select the source distribution\n",
    "p_y_init_idx = 0 ; p_y_init_label = \"Uniform\"\n",
    "#p_y_init_idx = 1 ; p_y_init_label = \"Tweak-2\"\n",
    "#p_y_init_idx = 2 ; p_y_init_label = \"Tweak-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_appendix = \"_eps_%s_init_%d.npy\" % (str(max_dist_thr), p_y_init_idx)\n",
    "# SUCCES AND FOOLING RATE\n",
    "success_optimization = np.load(load_path + \"success_opt\"       + param_appendix)\n",
    "fooling_rates        = np.load(load_path + \"fr\"                + param_appendix)\n",
    "opt_fooling_rate     = np.load(load_path + \"opt_fr\"            + param_appendix)\n",
    "# KULLBACK-LEIBLER\n",
    "kl_diver_obj       = np.load(load_path + \"kl_obj\"            + param_appendix)\n",
    "# DISTANCE BASED METRICS\n",
    "max_diff_obj       = np.load(load_path + \"max_dif_obj\"       + param_appendix)\n",
    "mean_diff_obj      = np.load(load_path + \"mean_dif_obj\"      + param_appendix)\n",
    "# CORRELATION\n",
    "spearman_obj = np.load(load_path + \"spearman_obj\"  + param_appendix)\n",
    "\n",
    "# SAVED ORIGINAL / ADVERSARIAL CLASSES\n",
    "save_orig_classes  = np.load(load_path + \"save_orig_classes\" + param_appendix)\n",
    "save_adv_classes   = np.load(load_path + \"save_adv_classes\"  + param_appendix)\n",
    "\n",
    "# PVALUES\n",
    "pval_orig_checks = np.load(load_path + \"pval_orig_checks\"  + param_appendix)\n",
    "pval_adv_checks  = np.load(load_path + \"pval_adv_checks\"   + param_appendix)\n",
    "checkpoints      = np.load(load_path + \"checkpoints\"       + param_appendix)\n",
    "\n",
    "# INITIAL AND SET OF TARGET DISTRIBUTIONS\n",
    "p_y_init    = np.load(load_path + \"p_y_init\"       + param_appendix)\n",
    "p_y_obj_set = np.load(load_path + \"p_y_obj_set\"    + param_appendix)\n",
    "\n",
    "# AUXILIARY INFORMATION\n",
    "py_test_tol   = np.load(load_path + \"py_tolerance\" + param_appendix)\n",
    "\n",
    "\n",
    "assert np.all(success_optimization==1) #Sanity check\n",
    "\n",
    "\n",
    "# Number of cases in which our method managed to avoid the shift detector (for all the checks)\n",
    "mask_pval_mid = np.all(pval_adv_checks>py_test_tol, axis=1)\n",
    "assert len(mask_pval_mid)==len(p_y_obj_set) #Sanity check\n",
    "perc_success_mid = np.sum(mask_pval_mid)/len(mask_pval_mid)*100\n",
    "\n",
    "\n",
    "# Similarity metrics (considering only those cases in which our method managed to avoid the shift detector)\n",
    "avg_fr       = np.mean(fooling_rates[mask_pval_mid])\n",
    "avg_kl_dif   = np.mean(kl_diver_obj[mask_pval_mid])\n",
    "avg_max_dif  = np.mean(max_diff_obj[mask_pval_mid])\n",
    "avg_mean_dif = np.mean(mean_diff_obj[mask_pval_mid])\n",
    "\n",
    "\n",
    "#Print information in tabular format\n",
    "print(\"%s & %.2f & %.2f & %.2f &  %.2f / %.2f / %.2f \\\\\\\\\"%(p_y_init_label, \n",
    "                                                            perc_success_mid,\n",
    "                                                            avg_fr*100,\n",
    "                                                            opt_fooling_rate*100,\n",
    "                                                            avg_kl_dif, avg_max_dif, avg_mean_dif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
